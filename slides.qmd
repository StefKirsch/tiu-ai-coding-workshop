---
title: "ğŸ¤–ğŸ˜ Feel the Vibes: AI-assisted Coding"
format:
  revealjs:
    theme: default
    css:  styles-overrides.css  
    slide-number: true
    progress: true
    toc: false
    toc-depth: 1
    incremental: false
    smaller: true               # global smaller font size
    scrollable: true
bibliography: references.bib
suppress-bibliography: true
output-file: index
editor: visual
---

# Introduction and basics {.center style="text-align:center;"}

## ğŸ¤– Using AI to produce software

\

::::columns
::: {.column width="48%"}
### âœ¨ Why is AI so good at Coding?

-   Lots of **code** and **documentation** online
-   Relatively clear rules
-   ... but it is truly amazing
:::

::: {.column width="4%"}
:::

::: {.column width="48%"}
### ğŸ¦¾ How well is AI actually doing?

-   LLMs can do more and more complex tasks
-   Reliability issues remain (more on that later)\
â†’ Crucial to **understand**, **tweak** and **test** *your* code
:::
::::

## ğŸ« The two paradigms of AI Coding

\

::: columns
::: column

### AI-assisted Coding

-   AI makes suggestions
-   User takes all decisions 

:::
::: column
### Vibe Coding

-   User specifies the requirements
-   AI *agent* produces and takes decisions
:::
:::

\

::: callout-note
## Find a good balance

We want you to *feel the vibes* here, not *surrender* to them.

:::

## ğŸ“ Research Software Management

\

::: columns
::: {.column width="40%"}
Writing code is just the first step!

Make it FAIR with the help of good **Research Software Management**:

-   Version Control
-   Dependency Management
-   Add a license
-   Make sure it's reproducible\
â†’ Trustworthiness of your code

You can find an example project and a link to an checklist in the description.

:::

::: {.column width="60%"}
![Netherlands eSciecne Center and DANS. Five Recommendations for FAIR Software https://fair-software.nl/](images/fair-software.png){width="80%"}
:::
:::

## ğŸ¤– The inner workings of LLMs

\

::: columns
::: column
### Tokens

-   Smallest unit of text for the model
-   Typically 3 - 4 characters
-   LLM = next token prediction
:::

::: column
### Prompt and Output Cycle

1.  Prompt is added to the end of the conversation
2.  Model is signaled to respond â†’ Output

â†’ Prompts and Outputs = Context
:::
:::

## ğŸ¤” Plain LLM VS Reasoning Models

\

::: columns
::: {.column width="45%"}
### Standard LLM

-   Produces output token by token
-   All logic is applied ad-hoc and internally
-   Outputs are created based on the available *context*
:::

::: {.column width="10%"}
:::

::: {.column width="45%"}
### Reasoning model

-   Have been trained to make use of an internal "scratchpad"
-   Allows the AI to
    -   make a plan
    -   temporarily store information
    -   explore different avenues
    -   re-assess potential answers
-   Can access the web

:::
:::

## Plain LLM VS Reasoning Models {.no-scroll}

![](images/non-reasoning.png){width="900" style="max-height:unset;"}

## ğŸ¤” Plain LLM VS Reasoning Models {.no-scroll}

![](images/reasoning.png){width="900" style="max-height:unset;"}

## â” When to use which type of model

\

::: columns
::: column
### Standard LLM

-   "Small" questions (e.g. on syntax)
-   Whenever there is little context
-   Writing
-   ...
:::

::: column
### Reasoning models

-   Case-specific requests
-   Web search, literature research
-   Exploration of areas that are new to you
-   Whenever the standard LLM fails
-   ...
:::
:::

::: callout-tip
## Best practice

Play around with different models in different cases and get a feeling for yourself.
:::

## ğŸ•´ What is an Agent then? {.no-scroll}

\

::::columns
:::column
### General definition
Something that has ...

1.   **a goal**
2.   can take **actions in the real world**
:::
:::column
### Narrow definition

A meta-LLM that can ...

1.  call other **tools** (web search, Python, other LLMs)
2.  can access the command line and can write files

â†’ Allows autonomous workflows
:::
::::

::: callout-note
Modern reasoning LLMs (e.g. ChatGPT 5 Thinking) have agentic capabilities built in.
:::

## ğŸ”€ Ways of coding with an LLM{.center style="text-align:center;"}

## ğŸ”€ Chatbot

\

::: columns
::: {.column width="40%"}
### âœ… Pros 

- Model choice
- Iterate on prompts
- Lots of control\
including which data you enter)\
â†’ *GDPR compliance*

### âŒ Cons 

-   Copy-pasting
-   No further automation
-   Only aware of the context you give it
:::

::: {.column width="60%"}

![](images/levart_photographer-drwpcjkvxuU-unsplash.jpg)
:::
:::

## ğŸ”€ IDE plugins {.no-scroll}

\

::: columns
::: column
### âœ… Pros 

-   Automation
-   Context-aware of your codebase
-   Different modes of interaction (autocomplete, chat)
:::

::: column
### âŒ Cons 

-   No control over what gets transmitted\
    â†’ critical for GDPR and IP
-   Can get expensive for API calls
:::
:::

![](images/autocomplete.png){width="80%" fig-align="center"}

## ğŸ”€ Agents (Vibe Coding)

\

::::columns
::: {.column width="40%"}
-   Goal + write access to your codebase
-   Automatically calls API with prompts.
:::

::: {.column width="60%"}
![](images/claude-code.png){fig-align="center"}
:::

::::

## ğŸ”§ Prompt "engineering"

\

:::: columns
::: {.column width="45%"}
### ğŸ¤” What to ask for

-   Mindset: Ask for advice, not for solutions
-   Either very broad or very specific
-   Ask for a battle plan
    -   Think in building blocks
    -   Assemble them yourself
:::

::: {.column width="10%"}
:::

::: {.column width="45%"}
### ğŸ’¡ How to ask

-   Tell it all it needs to know
-   "How do I do xyz?" instead of "Do xyz for me."
-   Be specific in your requirements (you can discuss them before with AI)
:::
::::

::: callout-tip
## Your role

Product manager and quality assurance
:::

\

## ğŸ¤ª Quirks of LMMs

-   Vast experience in nearly every technology... 
-   But they haven't worked with any of them for a while
-   They are quick to draw conclusions from "faint" memory
-   Can't admit to not being sure about something
-   Tend to overcomplicate things
-   Quick to introduce redundant technologies\
â†’ Risk of technical debt

## ğŸ˜ Some alternative approaches

\

Proper coding skills still cannot be replaced by AI.

-   Visit courses, workshops and Coding CafÃ©s
-   Look for a role model and their work
-   Articles and tutorials, e.g.
    -   vignettes of R packages with\
`browseVignettes(package = "PACKAGENAME")`
    -   Turing Way 
-   The developer's documentation

::: callout-tip
Documentation should always be your "True North".
:::

## Questions? {.center style="text-align:center;"}

# Applicable Guidelines and Regulations {.center style="text-align:center;"}

## ğŸš¨ Why is AI potentially problematic?

\

::: columns
::: column
### ğŸ”’ Data safety

-   Need to run in the cloud
-   Not European
-   New

::: 
::: column
:::
:::

## Is AI really special? {.center style="text-align:center;"}

## ğŸš¨ Why is AI potentially problematic?

\

::: columns
::: column
### ğŸ”’ Data safety

-   Need to run in the cloud
-   Not European
-   New
:::

::: column
### ğŸ“ Integrity

-   GenAI will happily attempt to do anything
-   Obscure failure modes
    -   Hallucinations
    -   Lack of self-criticism
-   Plagiarism?
-   More material can be created faster
    -   Bigger chance of mistakes
    -   Greater potential for forgery
:::
:::

## ğŸ”’ Working with sensitive data {.no-scroll}

\

::::columns
::: {.column width="48%"}
### Research often involves sensitive data, such as

-   Personal identifiable information (name, age, emails, ...)
-   Special personal data (medical data, ethnicity, ...)
-   Trade secrets, NDA-protected data
-   ...
:::

::: {.column width="4%"}
:::

::: {.column width="48%"}
### Top ways of using AI with sensitive data 

1. Only enter metadata (column names, number of rows, aggregated data, etc.)
2. Synthetic data
3. Use specialized packages that run locally or in a protected cloud 
4. Use local AI models (e.g. JanAI)

:::
::::

:::callout-tip
In most cases, the LLM does not need to see the actual data.
:::

## ğŸ“ University guidelines

\

:::: columns
::: {.column width="40%"}

### General

-   [Information security policy](https://www.tilburguniversity.edu/about/conduct-and-integrity/privacy-and-security/information-security)
-   [Knowledge security](https://www.tilburguniversity.edu/about/conduct-and-integrity/privacy-and-security/knowledge-security)
-   [Data protection](https://www.tilburguniversity.edu/about/conduct-and-integrity/privacy-and-security/privacy-policy)

### GPAI specific

-   [AI guidelines for researchers](https://www.tilburguniversity.edu/intranet/organization-policy/strategy/infrastructure/research-infrastructure/ai-guidelines-researchers)

Guidelines are there to help you
:::

::: {.column width="5%"}
:::

::: {.column width="55%"}
![](images/tilburg-university-logo.png){width="40%" fig-align="center"}
:::
::::

## ğŸ“š National and EU law

\

### Laws that we all have to follow

-   GDPR
-   Intellectual property rights
-   EU AI Act
-   ...

## ğŸ“ Research integrity

\

### For GenAI use in particular 

-   No fraudulent activities

    -   Data fabrication
    -   Manipulation of data, analyses and results

-   Ensure reproducibility and transparency

    -   [Data Handling and Methods Reporting](https://www.tilburguniversity.edu/research/social-and-behavioral-sciences/science-committee) (TSB)
    -   [Guideline Replication Package](https://www.tilburguniversity.edu/research/economics-and-management/replication-package) (TiSEM)

:::callout-tip
Integrity principles also apply to **code**!
:::


## ğŸ“š Rules of funders and journals

\

::::columns
::: {.column width="48%"}
### NWO

-   Generative AI allowed for application
-   No restriction on AI use

Rules might differ per funder!

:::

::: {.column width="4%"}
:::

::: {.column width="48%"}
### Journals

GenAI policies vary a lot. E.g....

-   No restriction on AI use at all

-   Required statement on AI use

-   Exact list of AI models *and* prompts

    -   as soon as it touches data *or*
    -   when used to develop code and the analysis methods
:::
::::

## ğŸ“š Rules of funders and journals

\

\

::: callout-tip
### Our Recommendation

-   Stick to the most strict guidelines of relevant funders & journals in your field

-   Look up best practices and ask for advice on how to do so
:::

## ğŸŒ Common compliance slips {.no-scroll}

::::columns
:::column

::: callout-important
## GDPR applies to all personal data

There is no distinction between 

-   *publicly available* and 
-   *non-publicly available* data.

E.g. Social Media, Websites etc.
:::

:::

:::column

::: callout-important
## Data transfer via automated systems

- Watch out when you can't inspect and approve the prompts and input.

- They might transfer *sensitive data* without your knowledge!

- Examples are: IDE plugins and Vibe-Coding tools.
:::
:::
::::

## ğŸ’¡ Summary

-   Local guidelines and checklists
-   Compliance with national and EU legislation
-   Research integrity and clear end responsibility
-   Rules of funders and journals
-   Avoid compliance slips

::: callout-tip
## Ask for advice!

Talk to your school's Information Manager, Data Stewards or the central Research Data Office for [support](https://www.tilburguniversity.edu/intranet/research-support-portal/rdm/advice).
:::

# Best Practices {.center style="text-align:center;"}

## ğŸ˜µ Which model do I use? {.no-scroll}

\

:::: columns
::: {.column width="48%"}

### How the UI looked like before

-   Different models for different tasks.

-   *4o* series for writing/ planning.

-   *o3*, *o4* for coding and logical reasoning.
:::

::: {.column width="4%"}
:::

::: {.column width="48%"}
![](images/choice_of_models.png){height="50%"}
:::
::::

## ğŸ˜µ Which model do I use?

\

![](images/GPT5.png)

## ğŸ‘¥ Version control with Git {.no-scroll}

\

### Challenges in software development (with and without AI)

:::: columns
::: {.column width="50%"}

-   Saving makes iterations instantly permanent.

-   Changes can break working code.

-   High mental load to grasp code base and its development.

-   Ad-hoc versioning (e.g. with filenames) is cumbersome.

â†’ Issues get exacerbated by AI-assisted coding.
:::

::: {.column width="50%"}
:::
::::

## ğŸ‘¥ Version control with Git

\

::: columns
::: {.column width="50%"}
### Git allows you to...

-   Track changes to your code.

-   Manage versions with meaningful descriptions.

-   Back up your work safely in the cloud (GitHub, GitLab...) 
:::

::: {.column width="50%"}

![Image created with ChatGPT and edited](images/a94yru.jpg){width="700" style="max-height:unset;"}
:::
:::

## ğŸ‘¥ Version control with Git

\

:::: columns
::: {.column width="48%"}

### Preview changes before comitting

- Valuable to maintain code hygiene
- Extra gate for code to become definitive.
- Spot "improvements" your code, that you did not prompt for.
- A chance to review the code, the syntax and style before accepting it.
:::

::: {.column width="4%"}
:::

::: {.column width="48%"}


![](images/git_diff_5.png)
:::
::::

## ğŸš« How to (not) write code with AI  {.center style="text-align:center;"}

## ğŸ¯ Beware of large tasks in one shot

![](images/chatgpt_meditation.png)

## ğŸ› Beware of bugs

AI produces overly eager results without really thinking them all the way through.

![](images/chatgpt_meditation2.png)

## ğŸ” Beware of vicious cycles

::::columns
::: {.column width="35%"}

\

-   You end up debugging code way more than you would like.

-   Takes longer overall (even if the start was quick)
:::

::: {.column width="5%"}
:::

::: {.column .right width="60%"}
![](images/a959dd.jpg){width="600" style="max-height:unset;"}
:::
::::

## âœ… How to have AI write code  {.center style="text-align:center;"}

## ğŸ¤ Narrow the scope

![](images/GPT5_specific_problem_1.png){width="700" style="max-height:unset;" fig-align="center"}

## ğŸ’¡ A tool to understand code {.no-scroll}

![](images/GPT5_understand_code_1.png)

## ğŸ Improving your own code base through feedback

![](images/GPT5_understand_code_2.png)

## ğŸ Improving your own code base through feedback

![](images/GPT5_understand_code_3.png)

## ğŸ Improving your own code base through feedback

![](images/GPT5_understand_code_4.png){width="30%"}

## ğŸ˜¯ Things to keep in mind

-   LLMs have very high standards (look into both major and very minor issues) 
-   Take feedback with a grain of salt.
-   More context of use-case â†’ better responses

## ğŸ“ Prompt engineering {.center style="text-align:center;"}

## Verbosity

-   Limit verbosity (in general), you can always dig for more if *you* want

![](images/GPT5_prompt_engineering_1.png)

## ğŸ¦œ Verbosity

![](images/GPT5_prompt_engineering_2.png){width="500"}

## ğŸ” Clarity over conciseness

-   Asking to focus on clarity over conciseness

![](images/GPT5_prompt_engineering_3.png){width="500"}

## ğŸ” Clarity over conciseness

![](images/GPT5_prompt_engineering_4.png){width="500"}

## ğŸ‘¹ Assigning roles

-   On assigning roles and more

    <iframe width="560" height="315" src="https://www.youtube.com/embed/X7YjqKk-7Y0?si=hYKV42m7p6FMOUWD" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen>

    </iframe>

<details>

<summary>More examples with resources</summary>

1.  [Ethan Mollick on prompt engineering](https://www.moreusefulthings.com/instructor-prompts)
2.  [TU Delft's wiki on prompting ChatGPT for researchers](https://hri-wiki.tudelft.nl/llm/chat-gpt-prompts)

</details>

## ğŸ§° Specialized packages

Rather than using the AI for your processing, look for specialized packages for a specific task.

-   More flexible
-   Safer
-   Often more accurate

Examples:

-  *Whisper* for accurate transcription of audio files.

-  *textwash* for anonymization of text data.


## ğŸ Using Projects

Projects are a fantastic aid in managing chats and using them mindfully.

-   Add specific context or media that ChatGPT will keep in its memory for future chats.
-   Better workflow for different projects with corresponding chats


![](images//Projects_callout.png){width="900" style="max-height:unset;"}

## â˜ƒï¸ When to take a break

::: columns
::: {.column width="35%"}
*Subtle* signs of frustration ...

\

-   Collaboration can turn into dependence: ***your problem is still yours to solve; with or without AI***
-   Consider alternatives sources

:::

::: {.column width="5%"}
:::

::: {.column width="60%"}
![](images/oversights.png)
:::
::::

# Pitfalls {.center style="text-align:center;"}

## âœ‚ Pitfall 1 - Taking shortcuts

<details>

<summary>Shortcuts often turn out costly in the end.</summary>

It is very tempting to just ask the AI to do a whole work package for you, especially when you are under time pressure. Even worse still, the code will probably work, which hides the potential cost in the long run.

The result is often code that doesn't fit the logic and style of the rest of your project, adds unnecessary dependencies or in some other way does not fit well into the bigger picture.

</details>

![](https://i.imgflip.com/a4v6za.jpg)

::: callout-tip
## Our Recommendation

Find a workflow that balances *efficiency* and *sustainability* and that works for you. Then stick to it.
:::

## ğŸ¥Š Pitfall 2 - Punching above your weight

::: {style="text-align:center"}
![](images/pitfall_2.png){width="900" style="max-height:unset;"}
:::

<details>

<summary>Only ask AI to do what you could also do yourself.</summary>

The sustainable route of using AI is to not have it write code that you could not have produced yourself. This of course doesn't mean that you can't ask AI **help you** write that code!

::: callout-tip
## Our Recommendation

We recommend that you only (fully) outsource tasks to AI that are basically trivial for you.
:::

</details>

<details>

<summary>Some tips for working on challenging problems using AI</summary>

-   [**Learn before you lean**](https://www.techradar.com/pro/the-genai-crutch-why-teams-must-learn-before-they-lean?utm_source=chatgpt.com): Understanding AI written code is the ***only*** way to write code with AI.

-   **Documentation is your best friend.** Writing comments for your code (what it does and why you chose a certain strategy) is the safest way to make it maintainable.

</details>

## ğŸ› Pitfall 3 - Context conundrums

::: columns
::: column
The context in the example of ChatGPT

-   The system prompt

-   Custom instructions

-   "Memory"

-   Project context

-   Your prompts and the model's responses (the conversation)

-   ....and more that isn't visible
:::

::: column
![](https://i.imgflip.com/a4uupf.jpg){width="500" style="max-height:unset;"}
:::
:::

## ğŸŒŠ Pitfall 3a - Context window overflow

<details>

<summary>LLMs can only remember so much</summary>

Especially in longer conversations, you can quickly exceed the functional context window, which is often much less than the nominal ones (e.g., 10k words for ChatGPT 5).

This means that the model will forget what was said earlier, especially if it was somewhere in the middle of the conversation.

</details>

![](https://i.imgflip.com/a4v4gn.jpg){width="500" style="max-height:unset;"}

## ğŸ· Pitfall 3b - Muddy the (context) water

<details>

<summary>A little context hygiene goes a long way.</summary>

Many of the advertised features, like "custom instructions," "memory," and "projects," boil down to adding extra context to the conversation history (aka context stuffing). In most cases, this is helpful and feels like genuine personalization that adds convenience. But it can also lead to strange outcomes when the AI can't quite decide which bit of the context is actually relevant at a given time. It can also change the behavior of the model in unexpected ways.

Unfortunately, all the extra context is typically hidden from the user, at least while chatting with the model. At the time of writing, however, most providers allow you to inspect, modify, or delete unwanted context fluff, albeit it being scattered across various corners of the UI. A quick web search or asking the AI of choice can typically help you identify and remove the culprits, though.

</details>

![](https://i.imgflip.com/a4v36z.jpg){width="500" style="max-height:unset;"}

## Questions? {.center style="text-align:center;"}

# Next steps

## Presentation Materials

::: columns
::: column
![](images/qr_slides.png){width="80%"}
:::

::: column
<details>

<summary>Want to learn more?</summary>

We added expandable sections like this one throughout the presentation. Here, you can find extra information and references for further reading and learning.

</details>
:::
:::

## Upcoming Events

### The Coding CafÃ©

Next session: October 23rd

::: columns
::: column
![](images/qr_coding_cafe.png){width="80%"}
:::

::: column
![](https://code-cafes-nl.github.io/cafe_playbook/images/tiu-cafe.jpg)
:::
:::

## Upcoming Events

### Open Science Game Nights - Data Horror Edition ğŸƒ

October 30th

::: columns
::: column
![](images/qr_game_night.png){width="65%"}
:::

::: column
![](https://dkou0skpxpnwz.cloudfront.net/accounts/173684/images/GHOST_games__1_.jpg){width="80%"}
:::
:::

