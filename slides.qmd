---
title: "ü§ñüòé Feel the Vibes: AI-assisted Coding"
format:
  revealjs:
    theme: default
    css:  styles-overrides.css  
    slide-number: true
    progress: true
    toc: true
    toc-depth: 1
    incremental: false
    smaller: true               # global smaller font size
    scrollable: true
bibliography: references.bib
suppress-bibliography: true
output-file: index
editor: visual
---

# Introduction and basics

## ü§ñ Using AI to produce software

### ‚ú® Why is AI so good at Coding?

-   Lots of **code** and **documentation** online
-   Relatively clear rules
-   ... but it is truly amazing

### ü¶æ How well is AI actually doing?

-   LLMs can do more and more complex tasks, see [Moore's Law for AI agents](https://theaidigest.org/time-horizons)
-   Reliability issues remain (more on that later)\
‚Üí Crucial to **understand**, **tweak** and **test** *your* code

## üìù The two paradigms of AI Coding

::: columns
::: column

**AI-assisted Coding**

-   AI makes suggestions
-   User takes all decisions 

**Vibe Coding**

-   User specifies the requirements
-   AI *agent* produces and takes decisions

<details>

<summary>*More info*</summary>

**AI‚Äëassisted coding** means using the AI as an assistant that helps you plan, write and understand code. You are still in the driver seat and have to make all important decisions. This is good, because it makes it easier (but not inevitable) that you understand what you actually produce.

**Vibe¬†Coding** goes further and delegates basically all decision-making to the AI. This can of course be very powerful, but it is basically impossible to understand what the code actually does and it can make it very challenging to fix bugs later on. Most importantly, it increases the risk of oversights that could then go completely unnoticed.

</details>

:::
::: column
<iframe src="https://giphy.com/embed/yIh6EVwpd2VJ6NbNNY" width="480" height="269" frameborder="0" class="giphy-embed" allowfullscreen>

</iframe>
:::
:::

::: callout-note
## Find a good balance

We want you to feel the vibes here, not surrender to them.

:::

## Research Software Management

::: columns
::: column
Writing code is just the first step!

Make it FAIR with the help of good <details>

<summary>Research Software Management.</summary>

When working with digital methods in research, you will encounter two types of software: Research Software and Software *in* Reseearch.

[@gruenpeter_2021_5504016](https://zenodo.org/records/5504016) came up with the following distinction in the FAIR4RS working group:

> ‚Äú**Research Software** includes **source code files, algorithms, scripts, computational workflows and executables** that were **created during the research process** or **for a research purpose**.
>
> Software components (e.g., operating systems, libraries, dependencies, packages, scripts, etc.) that are used **for research** but were **not created during or with a clear research intent** should be considered **software in research** and not Research Software.‚Äù

Both require Software Management and ideally a plan on how to do it. You can read more on the topic [here](https://zenodo.org/records/7589725#.Y-OMgHbMI2w).

</details>

-   Version Control
-   Dependency Management
-   Add a [license](https://choosealicense.com/)
-   Make sure it's reproducible\
‚Üí Trustworthiness of your code


Here is an [example project](https://github.com/StefKirsch/amazing_github_research_repo).

:::

::: column
![Martinez-Ortiz, C., Martinez Lavanchy, P., Sesink, L., Olivier, B. G., Meakin, J., de Jong, M., & Cruz, M. (2023). Practical guide to Software Management Plans (1.1). Zenodo. https://doi.org/10.5281/zenodo.7589725](images/smp.png){width="80%"}
:::
:::

## üß† Large Language Models (LLMs) in a nutshell {.center}

```{=html}
<iframe 
  width="600"
  height="400"
  src="https://www.youtube.com/embed/LPZh9BOjkQs?si=ifls2CZBbVzfF9nM" 
  title="YouTube video player" 
  frameborder="0" 
  allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share
  referrerpolicy="strict-origin-when-cross-origin" allowfullscreen>
</iframe>
```

## ü§ñ The inner workings of LLMs

::: columns
::: column
### Tokens

-   Smallest unit of text for the model
-   Typically 3 - 4 characters
-   LLM = next token prediction
:::

::: column
### Prompt and Output Cycle

1.  Prompt is added to the end of the conversation
2.  Model is signaled to respond ‚Üí Output

‚Üí Prompts and Outputs = Context
:::
:::

## ü§î Plain LLM VS Reasoning Models

::: columns
::: column
### Standard LLM

```{=html}
<iframe src="https://giphy.com/embed/tTyTbFF9uEbPW"
        width="480" height="270"
        style="display:block; margin:0 auto;"
        frameborder="0" allowfullscreen>
</iframe>
```
<details>

<summary>More info</summary>

Standard models produce output by producing tokens. Their context is the entire previous conversation, including the response that is currently generated.

All logic (‚Äúthinking‚Äù) happens internally and ad‚Äëhoc.

</details>
:::

::: column
### Reasoning model

```{=html}
<iframe src="https://giphy.com/embed/WTDvmZyUDlngcu7q5L"
        width="480" height="270"
        style="display:block; margin:0 auto;"
        frameborder="0" allowfullscreen>
</iframe>
```
<details>

<summary>More info</summary>

Reasoning models have the ability **and** have been specifically trained to produce tokens in **two phases**.

1.  Thinking tokens: These serve as a scratchpad, for making a plan, noting things down for later, taking notes of what didn't work etc. The model is aware that this is not part of the output. You can inspect this as the user, even though proprietary providers will typically show you a summary of the thinking process and not the whole output.

2.  The user-facing output: The model considers this as the "actual" output. This phase is basically how non-reasoning models operate, but in this case, we have all the notes from the previous phase, which can help a lot in producing a better result.

</details>
:::
:::

## ü§î Plain LLM VS Reasoning Models

![](images/non-reasoning.png){width="900" style="max-height:unset;"}

## ü§î Plain LLM VS Reasoning Models

![](images/reasoning.png){width="900" style="max-height:unset;"}

## ‚ùî When to use which type of model

::: columns
::: column
### Standard LLM

-   "Small" questions (e.g. on syntax)
-   Whenever there is little context
-   Writing
-   ...
:::

::: column
### Reasoning models

-   Case-specific requests
-   Web search, literature research
-   Exploration of areas that are new to you
-   Whenever the standard LLM fails
-   ...
:::
:::

::: callout-tip
## Best practice

Play around with different models in different cases and get a feeling for yourself.
:::

## üï¥ What is an Agent then? {.incremental}

-   **Standard definition**: Something that has
    1.  **a goal**
    2.  can take **actions in the real world**
-   **Narrow definition**: A meta-LLM that can
    1.  call other **tools** (Web search, Python, other LLMs)
    2.  can access the command line and can write files

‚Üí Allows autonomous workflows

::: callout-note
Modern reasoning LLMs (e.g. ChatGPT 5 Thinking) have agentic capabilities built in.
:::

## üîÄ Ways of coding with an LLM

### Chatbot

![](https://images.seeklogo.com/logo-png/50/1/chatgpt-logo-png_seeklogo-503286.png){width="15%"} ![](https://images.seeklogo.com/logo-png/61/1/microsoft-copilot-logo-png_seeklogo-619562.png){width="15%"} ![](https://images.seeklogo.com/logo-png/55/1/claude-logo-png_seeklogo-554540.png){width="15%"}

::: columns
::: column
#### Pros ‚úÖ

- Model choice
- Iterate on prompts
- Lots of control (including which\
data you enter)\
‚Üí *GDPR compliance*
:::

::: column
#### Cons ‚ùå

-   Copy-pasting
-   No further automation
-   Only aware of the context you give it
:::
:::

## üîÄ Ways of coding with an LLM

### IDE plugins

::: columns
::: column
#### Pros ‚úÖ

-   Automation
-   Context-aware of your codebase
-   Different modes of interaction (autocomplete, chat)
:::

::: column
#### Cons ‚ùå

-   No control over what gets transmitted\
    ‚Üí critical for GDPR and IP
-   Can get expensive for API calls
:::
:::

![](images/autocomplete.png){width="80%" fig-align="center"}

## üîÄ Ways of coding with an LLM

### Agents (Vibe Coding)

-   Goal + write access to your codebase
-   Automatically calls API with prompts.

![](images/claude-code.png){fig-align="center"}

## üîß Prompt "engineering"

Maybe a little overhyped...

<details>

<summary>More info</summary>

**Prompt engineering** is important when you ask an LLM for a complete solution or when you develop an application that routinely talks to an LLM API. In those cases phrasing and "strategic" considerations can make a big difference.

For day-to-day use and especially AI-assisted coding, you typically don't need to overthink (engineer) your prompts as long as you keep in mind a couple of things.

</details>

## üîß Prompt "engineering"

::: columns
::: column
### ü§î What to ask for

-   Mindset: Ask for advice, not for solutions
-   Either very broad or very specific
-   Ask for a battle plan
    -   Think in building blocks
    -   Assemble them yourself
:::

::: column
### üí° How to ask

-   Tell it all it needs to know

<details>

<summary>More info</summary>

Remember: AI can't read your mind! 

-   It doesn't know anything about you or your project 
-   ‚Ä¶ and even if it does, it probably it doesn‚Äôt know what that means

‚Üí Talk to AI like to a new colleague that still needs a lot of onboarding. Tell it what it needs to know and how to make sense of it.

</details>

-   "How do I do xyz?" instead of "Do xyz for me."
-   Be specific in your requirements (you can discuss them before with AI)
:::
:::

::: callout-tip
## Your role

Product manager and quality assurance
:::

## üîß Prompt "engineering"

<details>

<summary>The Prompt VS the Context</summary>

For longer, real‚Äëlife chats it‚Äôs often more useful to not think in prompts, but in the full **context**. The context is the full window of tokens the model can ‚Äúsee‚Äù, i.e. the chat history plus anything else the LLM provider adds to the context. LLMs have a limited context size, which means they will at some point "forget" what they saw earlier in the conversation.

</details>

![](https://i.imgflip.com/a5wktc.jpg){fig-align="center"}

## ü§™ Quirks of LMMs

-   Vast experience in nearly every technology... 
-   But they haven't worked with any of them for a while
-   They are quick to draw conclusions from "faint" memory
-   Can't admit to not being sure about something
-   Tend to overcomplicate things
-   Quick to introduce redundant technologies\
‚Üí Risk of technical debt

## üòé Some alternative approaches

Hard coding skills still cannot be replaced by AI.

-   Visit courses, workshops and Coding Caf√©s
-   Look for a role model and their work
-   Articles and tutorials, e.g.
    -   vignettes of R packages with\
`browseVignettes(package = "PACKAGENAME")`
    -   Turing Way 
-   The developer's documentation

::: callout-tip
Documentation should always be your "True North".
:::

## Questions? {.center style="text-align:center;"}

# Applicable Guidelines and Regulations

## üö® Why is AI use potentially problematic?

::: columns
::: column
### üîí Information, knowledge and data safety

-   Need to run in the cloud
-   Not European
-   New

<details>

<summary>Is AI really special?</summary>

All data protection considerations have to be made regardless of the fact whether a given system is considered **AI or not**. There is a common misconception that AI itself is the problem, e.g. because the models are trained on the prompts. **That is not correct**. Instead, the issue lies with **cloud-based systems** for which your institution/employer does not have a **data processing agreement** with the supplier.

</details>
:::

::: column
### üéì Integrity

-   GenAI will happily attempt to do anything
-   Obscure failure modes
    -   Hallucinations
    -   Lack of self-criticism
-   Plagiarism question
-   More material can be created faster
    -   Bigger chance of mistakes
    -   Greater potential for forgery
:::
:::

## üéì University guidelines

General

-   [Information security policy](https://www.tilburguniversity.edu/about/conduct-and-integrity/privacy-and-security/information-security)
-   [Knowledge security](https://www.tilburguniversity.edu/about/conduct-and-integrity/privacy-and-security/knowledge-security)
-   [Data protection](https://www.tilburguniversity.edu/about/conduct-and-integrity/privacy-and-security/privacy-policy)

GPAI specific

-   [AI guidelines for researchers](https://www.tilburguniversity.edu/intranet/organization-policy/strategy/infrastructure/research-infrastructure/ai-guidelines-researchers)

<details>

<summary>Guidelines are there to help you</summary>

In practice, it can be quite challenging to be and stay up to date with the latest regulations. University guidelines should be viewed as a practical interpretation for you as the end user. Unfortunately, the university can't relieve you from your legal and ethical responsibilities, so you should do your due diligence and check which rules and regulations apply in your situation.

</details>

## ‚öñ National and EU law

-   GDPR
-   Intellectual property rights
-   EU AI Act

## üéì Research integrity

<details>

<summary>Just as any research output, the same principles also apply to **code**!</summary>

In the past, **Research Software** has often been considered as a necessary intermediate product of research, but was often not worth mentioning or publishing. Times have changed though, and both Tilburg University, but also many funders and journals consider **Research Software** as a relevant and crucial output that is worth highlighting and discussing. This is for two reasons:

1.  From an Open Science and FAIR perspective, sharing your code creates the necessary transparency on how you got to your results, so that your research becomes trustworthy.
2.  Universities, funders and journals have noticed that we still often reinvent the wheel for new projects. Creating software that is easy to reuse in other projects can thus be enormously beneficial in advancing the science faster and significantly cheaper.

Software has been contributing to the results of published research for a long time, and has therefore always been subject to research integrity principles. In modern times though, we see more and more that integrity in software development is not only assumed anymore, but also tested for more and more.

</details>

In particular relevant for GenAI use:

-   No fraudulent activities

    -   Data fabrication
    -   Manipulation of data, analyses and results

-   Ensure reproducibility and transparency

    -   [Data Handling and Methods Reporting](https://www.tilburguniversity.edu/research/social-and-behavioral-sciences/science-committee) (TSB)
    -   [Guideline Replication Package](https://www.tilburguniversity.edu/research/economics-and-management/replication-package) (TiSEM)

## üìö Rules of funders and journals

NWO

-   Generative AI allowed for applicants

Journals: GenAI policies vary a lot. E.g....

-   No restriction on AI use at all

-   Required statement on AI use

-   Exact list of AI models *and* prompts

    -   as soon as it touches data *or*
    -   when used to develop code and the analysis methods

## üìö Rules of funders and journals

::: callout-tip
## Our Recommendation

-   Stick to the most strict guidelines of relevant funders & journals in your field

-   Don't bootstrap your own way of doing things. Look up best practices and ask for advice!
:::

## ‚õ∏ Common compliance slips

::: callout-important
## GDPR also applies to publicly available data

The GDPR makes no distinction between *publicly available* and *non-publicly available* data.

E.g. Social Media, Websites etc.
:::

::: callout-important
## Data transfer via automated systems

Beware of tools where you can't inspect and approve the prompts and input yourself.

They might transfer *sensitive data* without your knowledge!

Examples are: IDE plugins and Vibe-Coding tools.
:::

## üí° Summary

-   Local guidelines and checklists
-   Compliance with national and EU legislation
-   Research integrity and clear end responsibility
-   Rules of funders and journals
-   Avoid compliance slips

::: callout-tip
## Ask for advice!

Talk to your school's Information Manager, Data Stewards or the central Research Data Office for [support](https://www.tilburguniversity.edu/intranet/research-support-portal/rdm/advice).
:::

## Questions? {.center style="text-align:center;"}

# Break

# Best Practices

## üòµ Which model do I use?

::: columns
::: {.column width="50%"}
*How the UI looked before*

![](images/choice_of_models.png){height="50%"}
:::

::: {.column width="50%"}
-   Different models for different tasks.

-   4o series for writing/ planning.

-   o3, o4 mini and o4 mini high for coding and logical reasoning.
:::
:::

## üòµ Which model do I use?

![](images/GPT5.png)

-   Picks the appropriate model based on the task at hand!\*

<details>

<summary>\*More about this</summary>

-   GPT5 may not always do this. It is at best, using key words in your prompt to gauge task complexity (and deciding further course of action)
-   Sometimes it will think way too little and sometimes start reasoning about something it doesn't need reasoning for.
-   It is always an advantage to know a bit about the different models. This video tells you about them in detail and with use-cases.

<iframe width="560" height="315" src="https://www.youtube.com/embed/uluRM4yIras?si=3caDpUQO9zF904OO" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen>

</iframe>

</details>

## üë• Using version control and Git

**Without Git**

::: columns
::: {.column width="50%"}
::: columns
<iframe src="https://giphy.com/embed/2KAGlmkPywhZS" width="247" height="480" frameborder="0" allowfullscreen>

</iframe>
:::
:::

::: {.column width="50%"}
::: columns
##### Nightmare üëπ

-   You don't know why your code works or why it doesn't.

-   Difficulty maintaining versions.

-   No clue which version contains what changes.
:::
:::
:::

## üë• Using version control and Git

Git is a version control system designed to track changes in your source code during software development.

**With Git**

::: columns
::: {.column width="50%"}
![](https://i.imgflip.com/a64www.jpg){width="700" style="max-height:unset;"}
:::

::: {.column width="50%"}
##### *Struggle*, but for the right reasons ‚õπÔ∏è‚Äç‚ôÇÔ∏è

-   Git keeps every change safe and rewindable.

<!-- -->

-   You can always fall back to a working version.
:::
:::

<details>

<summary>Learn more about git and how you can use it</summary>

-   [A fantastic guide to using git and github](https://www.youtube.com/watch?v=RGOj5yH7evk&t=360s) üçè
-   [What is Gitlab and how it may be a better choice than Github](https://www.incredibuild.com/blog/gitlab-vs-github-comparison)?‚öñ

</details>

## üö¶ Using `git diff`

The command `git diff` tells you exactly what changed in your code.

::: callout-warning
# `git diff` and AI written code

-   Using `git diff` is crucial when using ChatGPT to write code.
-   Even with a near-perfect prompting, ChatGPT can create completely unrelated changes in your code.
:::

![](images/git_diff_1.png)

![](images/git_diff_2.png)

<details>

<summary>More on git diff</summary>

-   [Datacamp article on git diff](https://www.datacamp.com/tutorial/git-diff-guide)

</details>

## üö´ How to (not) have it write code

![](images/GPT5_context_1.png)

::: callout-note
## üèÜ Golden Rule 1

**Having little to no expertise/context into a problem will not lead to a fruitful collaboration with AI.**
:::

## üö´ How to (not) have it write code: cycle of debugging

-   Code provided doesn't run locally + features don't work:

![](images/GPT5_context_2.png)

![](images/GPT5_context_3.png)

## üö´ How to (not) have it write code: end results

-   You end up debugging ChatGPTs code way more than you would like.

-   Takes longer overall (even if the start was quick)

![](https://i.imgflip.com/a64vaj.jpg){width="600" style="max-height:unset;"}

## ‚úÖ How to have it write code

**1. Narrow the scope of the problem**

::: callout-note
## üèÜ Golden Rule 2

**Troubleshooting specific problems leads to meaningful conversations with AI.**
:::

![](images/GPT5_specific_problem_1.png){height="30%"}

## ‚úÖ How to have it write code

**2. üí° Understanding code with it**

![](images/GPT5_understand_code_1.png)

## ‚úÖ How to have it write code

3.  Improving your own code base with general feedback

![](images/GPT5_understand_code_2.png)

-   response:

![](images/GPT5_understand_code_3.png)

## ‚úÖ How to have it write code

3.  Improving your own code base with case-specific feedback

![](images/GPT5_understand_code_4.png){width="30%"}

## ‚úÖ How to have it write code: reminders

-   ChatGPT has very high standards (looks into both major and very minor issues) - take feedback with a grain of salt.
-   More context of use-case: better suited responses

![](https://i.imgflip.com/a64urh.jpg){width="500" style="max-height:unset;"}

## üìè Prompt engineering - verbosity

-   Limit verbosity (in general), you can always dig for more if *you* want

![](images/GPT5_prompt_engineering_1.png)

## üìè Prompt engineering - verbosity

![](images/GPT5_prompt_engineering_2.png){width="500"}

## üìè Prompt engineering - clarity over conciseness

-   Asking to focus on clarity over conciseness

![](images/GPT5_prompt_engineering_3.png){width="500"}

## üìè Prompt engineering - clarity over conciseness

![](images/GPT5_prompt_engineering_4.png){width="500"}

## üìè Prompt engineering - assigning roles

-   On assigning roles and more

    <iframe width="560" height="315" src="https://www.youtube.com/embed/X7YjqKk-7Y0?si=hYKV42m7p6FMOUWD" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen>

    </iframe>

<details>

<summary>More examples with resources</summary>

1.  [Ethan Mollick on prompt engineering](https://www.moreusefulthings.com/instructor-prompts)
2.  [TU Delft's wiki on prompting ChatGPT for researchers](https://hri-wiki.tudelft.nl/llm/chat-gpt-prompts)

</details>

## üôÑ Do the right thing

Look up specific packages that are able to accomplish your task before completely pinning it on ChatGPT. This is safer and can also be more accurate.

Examples:

1.  [OpenAI whisper](https://github.com/openai/whisper)- *transcribes audio files offline*

2.  [textwash](https://github.com/ben-aaron188/textwash/tree/main) - *anonymize text offline*

![](https://i.imgflip.com/a5je7z.jpg){width="500" style="max-height:unset;"}

## üèÅ Using Projects

![](images//Projects_callout.png){width="900" style="max-height:unset;"}

::: callout-tip
## Using Projects

I have found using projects to be a fantastic aid in managing my chats and using them mindfully.

-   Add specific context or media that ChatGPT will keep in its memory for future chats.
-   Better workflow for different projects with corresponding chats
:::

## ‚òÉÔ∏è When to take a break

-   *Subtle* signs of frustration

::: columns
::: {.column width="70%"}
![](images/GPT5_frustration_1.png)
:::

::: {.column width="30%"}
<iframe src="https://giphy.com/embed/y1WDIwAZRSmru" width="400" height="300" style frameBorder="0" class="giphy-embed" allowFullScreen>

</iframe>
:::
:::

::: columns
::: {.column width="60%"}
-   Collaboration turns into dependence: ***your problem is still yours to solve; with or without it***
:::

::: {.column width="40%"}
:::
:::

## Questions? {.center style="text-align:center;"}

# Pitfalls

## ‚úÇ Pitfall 1 - Taking shortcuts

<details>

<summary>Shortcuts often turn out costly in the end.</summary>

It is very tempting to just ask the AI to do a whole work package for you, especially when you are under time pressure. Even worse still, the code will probably work, which hides the potential cost in the long run.

The result is often code that doesn't fit the logic and style of the rest of your project, adds unnecessary dependencies or in some other way does not fit well into the bigger picture.

</details>

![](https://i.imgflip.com/a4v6za.jpg)

::: callout-tip
## Our Recommendation

Find a workflow that balances *efficiency* and *sustainability* and that works for you. Then stick to it.
:::

## ü•ä Pitfall 2 - Punching above your weight

::: {style="text-align:center"}
![](images/pitfall_2.png){width="900" style="max-height:unset;"}
:::

<details>

<summary>Only ask AI to do what you could also do yourself.</summary>

The sustainable route of using AI is to not have it write code that you could not have produced yourself. This of course doesn't mean that you can't ask AI **help you** write that code!

::: callout-tip
## Our Recommendation

We recommend that you only (fully) outsource tasks to AI that are basically trivial for you.
:::

</details>

<details>

<summary>Some tips for working on challenging problems using AI</summary>

-   [**Learn before you lean**](https://www.techradar.com/pro/the-genai-crutch-why-teams-must-learn-before-they-lean?utm_source=chatgpt.com): Understanding AI written code is the ***only*** way to write code with AI.

-   **Documentation is your best friend.** Writing comments for your code (what it does and why you chose a certain strategy) is the safest way to make it maintainable.

</details>

## üéõ Pitfall 3 - Context conundrums

::: columns
::: column
The context in the example of ChatGPT

-   The system prompt

-   Custom instructions

-   "Memory"

-   Project context

-   Your prompts and the model's responses (the conversation)

-   ....and more that isn't visible
:::

::: column
![](https://i.imgflip.com/a4uupf.jpg){width="500" style="max-height:unset;"}
:::
:::

## üåä Pitfall 3a - Context window overflow

<details>

<summary>LLMs can only remember so much</summary>

Especially in longer conversations, you can quickly exceed the functional context window, which is often much less than the nominal ones (e.g., 10k words for ChatGPT 5).

This means that the model will forget what was said earlier, especially if it was somewhere in the middle of the conversation.

</details>

![](https://i.imgflip.com/a4v4gn.jpg){width="500" style="max-height:unset;"}

## üê∑ Pitfall 3b - Muddy the (context) water

<details>

<summary>A little context hygiene goes a long way.</summary>

Many of the advertised features, like "custom instructions," "memory," and "projects," boil down to adding extra context to the conversation history (aka context stuffing). In most cases, this is helpful and feels like genuine personalization that adds convenience. But it can also lead to strange outcomes when the AI can't quite decide which bit of the context is actually relevant at a given time. It can also change the behavior of the model in unexpected ways.

Unfortunately, all the extra context is typically hidden from the user, at least while chatting with the model. At the time of writing, however, most providers allow you to inspect, modify, or delete unwanted context fluff, albeit it being scattered across various corners of the UI. A quick web search or asking the AI of choice can typically help you identify and remove the culprits, though.

</details>

![](https://i.imgflip.com/a4v36z.jpg){width="500" style="max-height:unset;"}

## Questions? {.center style="text-align:center;"}

# Next steps

## Presentation Materials

::: columns
::: column
![](images/qr_slides.png){width="80%"}
:::

::: column
<details>

<summary>Want to learn more?</summary>

We added expandable sections like this one throughout the presentation. Here, you can find extra information and references for further reading and learning.

</details>
:::
:::

## Upcoming Events

### The Coding Caf√©

Next session: October 23rd

::: columns
::: column
![](images/qr_coding_cafe.png){width="80%"}
:::

::: column
![](https://code-cafes-nl.github.io/cafe_playbook/images/tiu-cafe.jpg)
:::
:::

## Upcoming Events

### Open Science Game Nights - Data Horror Edition üéÉ

October 30th

::: columns
::: column
![](images/qr_game_night.png){width="65%"}
:::

::: column
![](https://dkou0skpxpnwz.cloudfront.net/accounts/173684/images/GHOST_games__1_.jpg){width="80%"}
:::
:::

