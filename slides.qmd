---
title: "🤖😎 Feel the Vibes: AI-assisted Coding"
format:
  revealjs:
    theme: default
    css:  styles-overrides.css  
    slide-number: true
    progress: true
    toc: false
    toc-depth: 1
    incremental: false
    smaller: true               # global smaller font size
    scrollable: true
bibliography: references.bib
suppress-bibliography: true
output-file: index
editor: visual
---

# 1. Introduction and basics {.center style="text-align:center;"}

## 🤖 Using AI to produce software

\

::::columns
::: {.column width="48%"}
### ✨ Why is AI so good at Coding?

-   Lots of **code** and **documentation** online
-   Relatively clear rules
-   ... but it is truly amazing
:::

::: {.column width="4%"}
:::

::: {.column width="48%"}
### 🦾 How well is AI actually doing?

-   LLMs can do more and more complex tasks
-   Reliability issues remain (more on that later)\
→ Crucial to **understand**, **tweak** and **test** *your* code
:::
::::

## 🐫 The two paradigms of AI Coding

\

::: columns
::: column

### AI-assisted Coding

-   AI makes suggestions
-   User takes all decisions 

:::
::: column
### Vibe Coding

-   User specifies the requirements
-   AI *agent* produces and takes decisions
:::
:::

\

::: callout-note
## Find a good balance

We want you to *feel the vibes* here, not *surrender* to them.

:::

## 📝 Research Software Management

\

::: columns
::: {.column width="40%"}
Writing code is just the first step!

Make it FAIR with the help of good **Research Software Management**:

-   Version Control
-   Dependency Management
-   Add a license
-   Make sure it's reproducible\
→ Trustworthiness of your code

You can find an example project and a link to an checklist in the description.

:::

::: {.column width="60%"}
![Netherlands eSciecne Center and DANS. Five Recommendations for FAIR Software https://fair-software.nl/](images/fair-software.png){width="80%"}
:::
:::

## 🤖 The inner workings of LLMs

\

::: columns
::: column
### Tokens

-   Smallest unit of text for the model
-   Typically 3 - 4 characters
-   LLM = next token prediction
:::

::: column
### Prompt and Output Cycle

1.  Prompt is added to the end of the conversation
2.  Model is signaled to respond → Output

→ Prompts and Outputs = Context
:::
:::

## 🤔 Plain LLM VS Reasoning Models

\

::: columns
::: {.column width="45%"}
### Standard LLM

-   Produces output token by token
-   All logic is applied ad-hoc and internally
-   Outputs are created based on the available *context*
:::

::: {.column width="10%"}
:::

::: {.column width="45%"}
### Reasoning model

-   Have been trained to make use of an internal "scratchpad"
-   Allows the AI to
    -   make a plan
    -   temporarily store information
    -   explore different avenues
    -   re-assess potential answers
-   Can access the web

:::
:::

## Plain LLM VS Reasoning Models {.no-scroll}

![](images/non-reasoning.png){width="900" style="max-height:unset;"}

## 🤔 Plain LLM VS Reasoning Models {.no-scroll}

![](images/reasoning.png){width="900" style="max-height:unset;"}

## ❔ When to use which type of model

\

::: columns
::: column
### Standard LLM

-   "Small" questions (e.g. on syntax)
-   Whenever there is little context
-   Writing
-   ...
:::

::: column
### Reasoning models

-   Case-specific requests
-   Web search, literature research
-   Exploration of areas that are new to you
-   Whenever the standard LLM fails
-   ...
:::
:::

::: callout-tip
## Best practice

Play around with different models in different cases and get a feeling for yourself.
:::

## 🕴 What is an Agent then? {.no-scroll}

\

::::columns
:::column
### General definition
Something that has ...

1.   **a goal**
2.   can take **actions in the real world**
:::
:::column
### Narrow definition

A meta-LLM that can ...

1.  call other **tools** (web search, Python,\
other LLMs)
2.  can access the command line and can write files

→ Allows autonomous workflows
:::
::::

::: callout-note
Modern reasoning LLMs (e.g. ChatGPT 5 Thinking) have agentic capabilities built in.
:::

## 🔀 Ways of coding with an LLM{.center style="text-align:center;"}

## 🔀 Chatbot

\

::: columns
::: {.column width="40%"}
### ✅ Pros 

- Model choice
- Iterate on prompts
- Lots of control\
including which data you enter)\
→ *GDPR compliance*

### ❌ Cons 

-   Copy-pasting
-   No further automation
-   Only aware of the context you give it
:::

::: {.column width="60%"}

![](images/levart_photographer-drwpcjkvxuU-unsplash.jpg)
:::
:::

## 🔀 IDE plugins {.no-scroll}

\

::: columns
::: column
### ✅ Pros 

-   Automation
-   Context-aware of your codebase
-   Different modes of interaction (autocomplete, chat)
:::

::: column
### ❌ Cons 

-   No control over what gets transmitted\
    → critical for GDPR and IP
-   Can get expensive for API calls
:::
:::

![](images/autocomplete.png){width="80%" fig-align="center"}

## 🔀 Agents (Vibe Coding)

\

::::columns
::: {.column width="40%"}
-   Goal + write access to your codebase
-   Automatically calls API with prompts.
:::

::: {.column width="60%"}
![](images/claude-code.png){fig-align="center"}
:::

::::

## 🔧 Prompt "engineering"

\

:::: columns
::: {.column width="45%"}
### 🤔 What to ask for

-   Mindset: Ask for advice, not for solutions
-   Either very broad or very specific
-   Ask for a battle plan
    -   Think in building blocks
    -   Assemble them yourself
:::

::: {.column width="10%"}
:::

::: {.column width="45%"}
### 💡 How to ask

-   Tell it all it needs to know
-   "How do I do xyz?" instead of "Do xyz for me."
-   Be specific in your requirements (you can discuss them before with AI)
:::
::::

::: callout-tip
## Your role

Product manager and quality assurance
:::

\

## 🤪 Quirks of LMMs

\

-   Vast experience in nearly every technology... 
-   But they haven't worked with any of them for a while
-   They are quick to draw conclusions from "faint" memory
-   Can't admit to not being sure about something
-   Tend to overcomplicate things
-   Quick to introduce redundant technologies\
→ Risk of technical debt

## 😎 Some alternative approaches

\

Proper coding skills still cannot be replaced by AI.

-   Visit courses, workshops and Coding Cafés
-   Look for a role model and their work
-   Articles and tutorials, e.g.
    -   vignettes of R packages with\
`browseVignettes(package = "PACKAGENAME")`
    -   Turing Way 
-   The developer's documentation

::: callout-tip
Documentation should always be your "True North".
:::

# 2. Applicable Guidelines and Regulations {.center style="text-align:center;"}

## 🚨 Why is AI potentially problematic?

\

::: columns
::: column
### 🔒 Data safety

-   Need to run in the cloud
-   Not European
-   New

Is AI really any special?

:::

::: column
### 🎓 Integrity

-   GenAI will happily attempt to do anything
-   Obscure failure modes
    -   Hallucinations
    -   Lack of self-criticism
-   Plagiarism?
-   More material can be created faster
    -   Bigger chance of mistakes
    -   Greater potential for forgery
:::
:::

## 🔒 Working with sensitive data {.no-scroll}

\

::::columns
::: {.column width="48%"}
### Research often involves sensitive data, such as

-   Personal identifiable information (name, age, emails, ...)
-   Special personal data (medical data, ethnicity, ...)
-   Trade secrets, NDA-protected data
-   ...
:::

::: {.column width="4%"}
:::

::: {.column width="48%"}
### Top ways of using AI with sensitive data 

1. Only enter metadata (column names, number of rows, aggregated data, etc.)
2. Synthetic data
3. Use specialized packages that run locally or in a protected cloud 
4. Use local AI models (e.g. JanAI)

:::
::::

:::callout-tip
In most cases, the LLM does not need to see the actual data.
:::

## 🎓 University guidelines

\

:::: columns
::: {.column width="40%"}

### General

-   Information security policy
-   Knowledge security
Data protection

### GPAI specific

-   AI guidelines for researchers

Guidelines are there to help you
:::

::: {.column width="5%"}
:::

::: {.column width="55%"}
![](images/tilburg-university-logo.png){width="40%" fig-align="center"}
:::
::::

## 📚 National and EU law

\

### Laws that we all have to follow

-   GDPR
-   Intellectual property rights
-   EU AI Act
-   ...

## 🎓 Research integrity

\

### For GenAI use in particular 

-   No fraudulent activities

    -   Data fabrication
    -   Manipulation of data, analyses and results

-   Ensure reproducibility and transparency

    -   Data Handling and Methods Reporting (TSB)
    -   Guideline Replication Package (TiSEM)

:::callout-tip
Integrity principles also apply to **code**!
:::


## 📚 Rules of funders and journals

\

::::columns
::: {.column width="48%"}
### NWO

-   Generative AI allowed for application
-   No restriction on AI use

Rules might differ per funder!

:::

::: {.column width="4%"}
:::

::: {.column width="48%"}
### Journals

GenAI policies vary a lot. E.g....

-   No restriction on AI use at all

-   Required statement on AI use

-   Exact list of AI models *and* prompts

    -   as soon as it touches data *or*
    -   when used to develop code and the analysis methods
:::
::::

## 📚 Rules of funders and journals

\

\

::: callout-tip
### Our Recommendation

-   Stick to the most strict guidelines of relevant funders & journals in your field

-   Look up best practices and ask for advice on how to do so
:::

## 🍌 Common compliance slips {.no-scroll}

\

::::columns
:::column

::: callout-important
## GDPR applies to all personal data

There is no distinction between 

-   *publicly available* and 
-   *non-publicly available* data.

E.g. Social Media, Websites etc.
:::

:::

:::column

::: callout-important
## Data transfer via automated systems

- Watch out when you can't inspect and approve the prompts and input.

- They might transfer *sensitive data* without your knowledge!

- Examples are: IDE plugins and Vibe-Coding tools.
:::
:::
::::

## 💡 Summary

\

-   Local guidelines and checklists
-   Compliance with national and EU legislation
-   Research integrity and clear end responsibility
-   Rules of funders and journals
-   Avoid compliance slips

::: callout-tip
## Ask for advice!

Talk to your school's Information Manager, Data Stewards or the central Research Data Office for support.
:::

# 3. Best Practices {.center style="text-align:center;"}

## 😵 Which model do I use? {.no-scroll}

\

:::: columns
::: {.column width="48%"}

### How the UI looked like before

-   Different models for different tasks.

-   *4o* series for writing/ planning.

-   *o3*, *o4* for coding and logical reasoning.
:::

::: {.column width="4%"}
:::

::: {.column width="48%"}
![](images/choice_of_models.png){height="50%"}
:::
::::

## 😵 Which model do I use?

\

![](images/GPT5.png)

## 👥 Version control with Git {.no-scroll}

\

### Challenges in software development (with and without AI)

:::: columns
::: {.column width="50%"}

-   Saving makes iterations instantly permanent.

-   Changes can break working code.

-   High mental load to grasp code base and its development.

-   Ad-hoc versioning (e.g. with filenames) is cumbersome.

→ Issues get exacerbated by AI-assisted coding.
:::

::: {.column width="50%"}
:::
::::

## 👥 Version control with Git

\

::: columns
::: {.column width="50%"}
### Git allows you to...

-   Track changes to your code.

-   Manage versions with meaningful descriptions.

-   Back up your work safely in the cloud (GitHub, GitLab...) 
:::

::: {.column width="50%"}

![Image created with ChatGPT and edited](images/a94yru.jpg){width="700" style="max-height:unset;"}
:::
:::

## 👥 Version control with Git

\

:::: columns
::: {.column width="48%"}

### Preview changes before comitting

- Valuable to maintain code hygiene
- Extra gate for code to become definitive.
- Spot "improvements" your code, that you did not prompt for.
- A chance to review the code, the syntax and style before accepting it.
:::

::: {.column width="4%"}
:::

::: {.column width="48%"}


![](images/git_diff_5.png)
:::
::::

## 🚫 How to (not) write code with AI  {.center style="text-align:center;"}

## 🎯 Beware of large tasks in one shot

![](images/chatgpt_meditation.png)

## 🐛 Beware of bugs

AI produces overly eager results without really thinking them all the way through.

![](images/chatgpt_meditation2.png)

## 🔁 Beware of vicious cycles

::::columns
::: {.column width="35%"}

\

-   You end up debugging code way more than you would like.

-   Takes longer overall (even if the start was quick)
:::

::: {.column width="5%"}
:::

::: {.column .right width="60%"}
![](images/a959dd.jpg){width="600" style="max-height:unset;"}
:::
::::

## ✅ How to have AI write code  {.center style="text-align:center;"}

## 🤏 Narrow the scope  {.no-scroll}

![](images/GPT5_specific_problem_1.png){width="700" style="max-height:unset;" fig-align="center"}

## 💡 A tool to understand code {.no-scroll}

![](images/GPT5_understand_code_1.png)

## 🏁 Asking for feedback

![](images/GPT5_understand_code_2.png){width="70%"}

## 🏁 Asking for feedback

![](images/GPT5_understand_code_3.png){width="70%"}

## 🏁 Asking for feedback

![](images/GPT5_understand_code_4.png){width="30%"}

## 😯 Things to keep in mind

\ 

\ 

-   LLMs have very high standards (look into both major and very minor issues) 
-   Take feedback with a grain of salt.
-   More context of use-case → better responses

## 📏 Prompt engineering {.center style="text-align:center;"}

## 🦜 Verbosity

![](images/GPT5_prompt_engineering_1.png)

## 🦜 Verbosity

![](images/GPT5_prompt_engineering_2.png){width="500"}

## 🔍 Clarity over conciseness

![](images/GPT5_prompt_engineering_3.png){width="500"}

## 🔍 Clarity over conciseness

![](images/GPT5_prompt_engineering_4.png){width="500"}

## 🧰 Specialized packages

\

Rather than using the AI for your processing, look for specialized packages for a specific task.

-   More flexible
-   Safer
-   Often more accurate

Examples:

-  *Whisper* for accurate transcription of audio files.

-  *textwash* for anonymization of text data.


## 📂 Using Projects

\

:::: columns

::: {.column width="35%"}
Projects are a fantastic aid in managing chats and using them mindfully.

-   Add specific context or media that ChatGPT will keep in its memory for future chats.
-   Better workflow for different projects with corresponding chats
:::

::: {.column width="5%"}
:::

::: {.column width="60%"}
![](images/projects.png)
:::

::::

## ☃️ When to take a break

::: columns
::: {.column width="35%"}

\

*Subtle* signs of frustration ...

-   Collaboration can turn into dependence: ***your problem is still yours to solve; with or without AI***
-   Consider alternatives sources

:::

::: {.column width="5%"}
:::

::: {.column width="60%"}
![](images/oversights.png)
:::
::::

# 4. Pitfalls {.center style="text-align:center;"}

## 🩳 Pitfall 1 - Taking shortcuts

:::: columns
::: {.column width="40%"}

\

Shortcuts often turn out costly in the end.

-   Technical debt
-   Mistakes and hallucinations

:::

::: {.column width="10%"}
:::

::: {.column width="50%"}
![](images/shortcuts.png)
:::
::::

::: callout-tip
## Our Recommendation

Find a workflow that works for you while balancing *efficiency* and *sustainability*. Then stick to it.
:::


## 🥊 Pitfall 2 - Punching above your weight

::::columns
::: {.column width="35%"}

### Remedies

-   Be intentional which packages and technologies you introduce
-   Get a feeling for them yourself
-   Code = your understanding + help from AI 
:::

::: {.column width="5%"}
:::

::: {.column width="60%"}
![](images/pitfall_2.png)
:::

::::

## 🤯 Pitfall 3 - Context conundrums {.no-scroll}

::: columns
::: column
The context in the example of ChatGPT

-   The system prompt

-   Custom instructions

-   "Memory"

-   Project context

-   Your prompts and the model's responses (the conversation)

-   ....and more that isn't visible
:::

::: column
![](images/context_1.png){width="80%"}
:::
:::

## 🌊 Context window overflow {.no-scroll}

:::: columns
::: {.column width="45%"}

\

-   LLMs come with a limited context window\
(e.g., 10k words for ChatGPT 5)

-   Context, instructions etc. further up in the conversation will be "forgotten"
:::

::: {.column width="10%"}
:::

::: {.column width="45%"}
![](images/context_2.png){width="80%"}
:::
::::

## 🐷 Muddy (context) water

\

-   AI providers often stuff context to "personalize" their product.
-   A lot of that extra context is hidden.

→ Can to lead to unexpected behavior.

→ Context hygiene becomes important.

## Thanks for watching! {.center style="text-align:center;"}
